---
---
### Workshop Learning Objectives (*Fundamentals of Deep Learning*)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PracticumAI/deep_learning)

#### Session 1
1. Define a neural network.
2. Describe how a neural network works.
3. Discuss where a neural network can be used.
4. Use a deep learning pre-trained model to classify an image.
5. Discuss TensorFlow.
6. Discuss NumPy.
7. Discuss ResNet.

#### Session 2
1. Explore history of neural network development.
2. Describe the basis of a neural network (neuron).
3. Identify and describe an artificial neuron (perceptron).
4. Discuss bias and weights.
5. Discuss deep networks.
6. Describe and identify activation functions.
7. Describe and simulate image processing in a small neural network.
8. Implement and train a perceptron using TensorFlow.

#### Session 3
1. Describe the purpose of gradient descent.
2. Describe the process of gradient descent.
3. Discuss error loss function.
4. Describe optimizers.
5. Describe chain rule.

***
#### Videos
[DL : Neural Networks - Getting Started](https://mediasite.video.ufl.edu/Mediasite/Play/31f4838bc2d84b97b46b46eadb0748621d)

[DL : Anatomy of a Neural Network](https://mediasite.video.ufl.edu/Mediasite/Play/372d802f29744e15b21f2c4273f45f831d)

#### Links
[Lawrence Moroney Video](https://www.youtube.com/watch?v=VwVg9jCtqaU)

#### Notes
1. Vanishing / exploding gradients problem (*Hands-On Machine Learning w/Sci-Kit Learn...*, p. 332 - ff)
2. Backpropagation Summary (*Learning Deep Learning, Eckman*, p. 89.)
3. Learning Rate Hyperparameter (*Deep Learning: A Visual Approach, Glassner*, p. 376.) -- Excellent example!

