---
title: "Performance Evaluation: Measuring the Effectiveness of Transfer Learning"
image: 'https://raw.githubusercontent.com/PracticumAI/practicumai.github.io/main/images/icons/practicumai_transfer_learning.png'
image-width: 80px
image-height: 80px
layout: full_page
---

Selecting a technique is just the beginning—evaluating its effectiveness is crucial to ensure the best results.

## Key Evaluation Metrics

| Metric | Description | Best Used For |
|--------|-------------|---------------|
| **Accuracy** | Measures the percentage of correctly classified samples. | Classification tasks |
| **Precision & Recall** | Precision measures how many predicted positives are correct; recall measures how many actual positives are identified. | Tasks with class imbalance (e.g., fraud detection, medical diagnosis) |
| **F1‑Score** | Harmonic mean of precision and recall. | General evaluation of classification performance |
| **Mean Average Precision (mAP)** | Measures precision across different IoU thresholds. | Object detection |
| **IoU (Intersection over Union)** | Measures the overlap between predicted and ground‑truth object bounding boxes. | Object detection, segmentation |

---

[Return to Module 3](03_evaluate_and_optimize.md) or [Continue to Common Transfer Learning Issues & Troubleshooting Strategies](03.5_common_tl_problems.md)